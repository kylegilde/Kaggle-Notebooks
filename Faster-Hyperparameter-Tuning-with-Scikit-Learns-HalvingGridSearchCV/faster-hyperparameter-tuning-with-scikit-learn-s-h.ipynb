{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Hyperparameter Tuning with Scikit-Learn's HalvingGridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are a Scikit-Learn fan, Christmas came a few days early in 2020 with the [release of version 0.24.0](https://scikit-learn.org/dev/auto_examples/release_highlights/plot_release_highlights_0_24_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-0-24-0-py). Among the new features are 2 [experimental](https://scikit-learn.org/dev/glossary.html#term-experimental) classes in the model_selection module that support faster hyperparameter optimization: [HalvingGridSearchCV](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) and [HalvingRandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV). \n",
    "\n",
    "Like their close cousins [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV), they use cross-validation to find optimal hyperparameters. However, instead of independently searching the hyperparameter-set candidates, the [successive halving](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html) \"search strategy starts evaluating all the candidates with a small amount of resources and iteratively selects the best candidates, using more and more resources.\" The default resource is the number of samples, but the user can set it to any positive-integer model parameter like gradient boosting rounds. Thus, the halving approach has the potential of finding good hyperparameters in less time.\n",
    "\n",
    "\n",
    "## My Experiment\n",
    "\n",
    "After reading through Scikit-Learn's \"[Comparison between grid search and successive halving](https://scikit-learn.org/dev/auto_examples/model_selection/plot_successive_halving_heatmap.html#sphx-glr-auto-examples-model-selection-plot-successive-halving-heatmap-py)\" example (which takes a grand total of 11 seconds to run), I was still unclear about the real-world impact of using the halving approach versus the grid search, so I decided to set up an experiment to answer the following questions:\n",
    "\n",
    "1. What percentage of time is saved when using HalvingGridSearchCV instead of GridSearchCV?\n",
    "\n",
    "2. Does HalvingGridSearchCV still select the same hyperparameter set that GridSearchCV does?\n",
    "\n",
    "I'm going to compare 3 hyperparameter searches: \n",
    "\n",
    "1. GridSearchCV\n",
    "\n",
    "2. HalvingGridSearchCV using the default \"n_samples\" `resource`\n",
    "    \n",
    "3. HalvingGridSearchCV using the CatBoost's \"n_estimators\" as the `resource`\n",
    "\n",
    "\n",
    "### Upgrade Scikit-Learn\n",
    "\n",
    "The first step is to upgrade your version of Scikit to 0.24.0 and make sure you can import the corrent version.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.0\n"
     ]
    }
   ],
   "source": [
    "# !! pip install scikit-learn --upgrade\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "\n",
    "I ran my tests using the [Kaggle's](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) Ames, IA house prices dataset. It has 1,460 observatons and 79 features. The dependent variable is the `SalePrice` of the home. I recommend reading [this notebook](https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python) if you are interested in some exploratory data analysis on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "\n",
    "DEP_VAR = 'SalePrice'\n",
    "train_df = pd.read_csv('../kaggle/input/house-prices-advanced-regression-techniques/train.csv')\\\n",
    "           .set_index('Id')\n",
    "            \n",
    "y_train = train_df.pop(DEP_VAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Pipeline & Model\n",
    "\n",
    "I also wrote a script called pipeline_ames.py. It instantiates a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) containing some feature transformations and the [CatBoostRegressor](https://catboost.ai/docs/concepts/python-reference_catboostregressor.html). I've ploted its visual representation below. (You can read more about my approach to feature engineering in my [previous post](https://towardsdatascience.com/building-columntransformers-dynamically-1-6354bd08aa54).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e773c8b3-e3ac-4beb-84c3-30a94fea57c4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e773c8b3-e3ac-4beb-84c3-30a94fea57c4\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('column_transformer',\n",
       "                 ColumnTransformer(n_jobs=4,\n",
       "                                   transformers=[('numeric_pipe',\n",
       "                                                  Pipeline(steps=[('functiontransformer',\n",
       "                                                                   FunctionTransformer(func=<function <lambda> at 0x000002DFB6A194C0>)),\n",
       "                                                                  ('simpleimputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 strategy='median'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000002DFB6A...\n",
       "                                                                   FunctionTransformer(func=<function <lambda> at 0x000002DFB6A194C0>)),\n",
       "                                                                  ('simpleimputer',\n",
       "                                                                   SimpleImputer(strategy='constant')),\n",
       "                                                                  ('onehotencoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000002DFB9D61250>)])),\n",
       "                ('variancethreshold', VarianceThreshold()),\n",
       "                ('model',\n",
       "                 <catboost.core.CatBoostRegressor object at 0x000002DFBAC4F310>)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0e37da2b-2208-4dd6-92f2-18beb3e678ad\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0e37da2b-2208-4dd6-92f2-18beb3e678ad\">column_transformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(n_jobs=4,\n",
       "                  transformers=[('numeric_pipe',\n",
       "                                 Pipeline(steps=[('functiontransformer',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x000002DFB6A194C0>)),\n",
       "                                                 ('simpleimputer',\n",
       "                                                  SimpleImputer(add_indicator=True,\n",
       "                                                                strategy='median'))]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x000002DFB6AACEB0>),\n",
       "                                ('oh_pipe',\n",
       "                                 Pipeline(steps=[('functiontransformer',\n",
       "                                                  FunctionTransformer(func=<function <lambda> at 0x000002DFB6A194C0>)),\n",
       "                                                 ('simpleimputer',\n",
       "                                                  SimpleImputer(strategy='constant')),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x000002DFB9D61250>)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"09987516-b2c5-4756-9b12-21c2d6f6e916\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"09987516-b2c5-4756-9b12-21c2d6f6e916\">numeric_pipe</label><div class=\"sk-toggleable__content\"><pre><sklearn.compose._column_transformer.make_column_selector object at 0x000002DFB6AACEB0></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1b1bff76-aaa6-4b15-aec1-599ffde83d48\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1b1bff76-aaa6-4b15-aec1-599ffde83d48\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function <lambda> at 0x000002DFB6A194C0>)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ceca40a7-e75b-494e-90fa-64ade6d025b3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ceca40a7-e75b-494e-90fa-64ade6d025b3\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(add_indicator=True, strategy='median')</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5dc61014-f159-4f49-ac68-7a1ca3dd56e8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5dc61014-f159-4f49-ac68-7a1ca3dd56e8\">oh_pipe</label><div class=\"sk-toggleable__content\"><pre><sklearn.compose._column_transformer.make_column_selector object at 0x000002DFB9D61250></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"906a4a5c-f2f9-4809-b67b-b2177a386928\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"906a4a5c-f2f9-4809-b67b-b2177a386928\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=<function <lambda> at 0x000002DFB6A194C0>)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"fe1561dc-cacb-4779-95a7-4c821c7500ad\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"fe1561dc-cacb-4779-95a7-4c821c7500ad\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"de70249d-1d79-4475-aab4-6ff6f182fc34\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"de70249d-1d79-4475-aab4-6ff6f182fc34\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"61be288b-16eb-4f53-b82f-b47934ac121b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"61be288b-16eb-4f53-b82f-b47934ac121b\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d412c005-6d17-47b7-a77a-0105a3202dd4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d412c005-6d17-47b7-a77a-0105a3202dd4\">CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre><catboost.core.CatBoostRegressor object at 0x000002DFBAC4F310></pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import set_config                      # to change the display\n",
    "from sklearn.utils import estimator_html_repr       # to save the diagram into HTML format\n",
    "from IPython.core.display import display, HTML      # to visualize pipeline\n",
    "\n",
    "from pipeline_ames import pipe\n",
    "set_config(display='diagram')\n",
    "display(HTML(estimator_html_repr(pipe)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Controls \n",
    "\n",
    "The `grid_search_params` dictionary contains the control parameters that will be used in each of our trials. We are going to perform 3-fold cross-validation across a `param_grid` containing 4 [CatBoost hyperparameters](https://catboost.ai/docs/concepts/python-reference_parameters-list.html) with 3 values each. The results will be measured in root mean squared log error (RMSLE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error, make_scorer\n",
    "\n",
    "np.random.seed(123) # set a global seed\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "root_mean_squared_log_error = lambda y_true, y_pred: np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "scorer = make_scorer(root_mean_squared_log_error, greater_is_better=False)\n",
    "\n",
    "param_grid = {\"model__max_depth\": [5, 6, 7],\n",
    "              'model__learning_rate': [.01, 0.03, .06],\n",
    "              'model__subsample': [.7, .8, .9],\n",
    "              'model__colsample_bylevel': [.8, .9, 1]}\n",
    "\n",
    "grid_search_params = dict(estimator=pipe,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring=scorer,\n",
    "                          cv=3,\n",
    "                          n_jobs=-1,\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "### 1. GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline exhaustive grid search took nearly 30 minutes to perform 3-fold cross-validation on our 81 candidates. We will to see if the HalvingGridSearchCV process can find the same hyperparameters in less time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "full_results = GridSearchCV(**grid_search_params).fit(train_df, y_train)\n",
    "pd.DataFrame(full_results.best_params_, index=[0]).assign(RMSLE=-full_results.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. HalvingGridSearchCV with n_samples\n",
    "\n",
    "In first halving grid search, I used the following parameters:\n",
    "\n",
    "- The default 'n_samples' for the `resource`: This means that the number of training observations will start out small and increase with each iteration\n",
    "\n",
    "- A `factor` of 2: At the end of an interation, the top half of candidates with be retained and bottom half of candidates will be thrown out. It also means that the next interation will use twice the number of samples. \n",
    "\n",
    "- A quarter of the training samples for `min_resources`:  I did not use the default `min_resources` calculation of 22 samples because it produced terrible results. \n",
    "\n",
    "Sidenote: If you want the final iteration to use all of the samples, you will need to set  `min_resources` and `factor` to be factors of `max_resources`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv  \n",
    "from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV\n",
    "FACTOR = 2\n",
    "MAX_RESOURCE_DIVISOR = 4\n",
    "\n",
    "n_samples = len(train_df)\n",
    "halving_results_n_samples =\\\n",
    "    HalvingGridSearchCV(resource='n_samples',\n",
    "                        min_resources=n_samples // MAX_RESOURCE_DIVISOR,\n",
    "                        factor=FACTOR,\n",
    "                        **grid_search_params\n",
    "                        )\\\n",
    "                        .fit(train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This search did not produce good results. It actually took 5 minutes longer than the exhaustive search. Using my `compare_cv_best_params` function, we see that it found only the ninth optimal hyperparameter set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from compare_functions import *\n",
    "\n",
    "compare_cv_best_params(full_results, *[halving_results_n_samples])\\\n",
    "    .style.apply(lambda row: ['background: red' if row.name == 1 \\\n",
    "                              and col.name == 'full_grid_search_rank' else ''\\\n",
    "                              for col in row], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HalvingGridSearchCV with n_estimators\n",
    " \n",
    "In the second halving search, I used CatBoost's 'n_estimators' as the `resource` and set the first iteration to use a quarter of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "halving_results_n_estimators =\\\n",
    "    HalvingGridSearchCV(resource='model__n_estimators',                         \n",
    "                         max_resources=1000,\n",
    "                         min_resources=1000 // MAX_RESOURCE_DIVISOR,\n",
    "                         factor=FACTOR,\n",
    "                        **grid_search_params\n",
    "                        )\\\n",
    "                        .fit(train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This halving search produced the results that we were hoping to see. It was about 23% faster than the exhaustive grid search, and it found the best set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_cv_best_params(full_results, *[halving_results_n_samples, \n",
    "                                       halving_results_n_estimators])\\\n",
    "    .style.apply(lambda row: ['background: lightgreen' if row.name == 2 else '' \\\n",
    "                              for col in row], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The results of my HalvingGridSearchCV experiment were mixed. Using the default \"n_samples\" `resource` yielded slow and suboptimal results. If you are using an efficient model like CatBoost, limiting the number of samples may not save you any time. However, using CatBoost's `n_estimators` yielded the optimal results in less time. This tracks with my own experience manually tuning CatBoost hyperparameters. I can usually tell pretty quickly from the validation logs whether the hyperparameter set is worth fully exploring.\n",
    "\n",
    "The original notebook for this blog post can be found [here](https://www.kaggle.com/kylegilde/extracting-scikit-feature-names-importances). Stay tuned for further posts on training & regularizing models with Scikit-Learn. Let me know if you found this post helpful. Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
